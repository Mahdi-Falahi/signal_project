{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "c52d8f99",
            "metadata": {},
            "source": [
                "<div align=\"center\">\n",
                "  <a href=\"http://www.sharif.edu/\">\n",
                "    <img src=\"https://cdn.freebiesupply.com/logos/large/2x/sharif-logo-png-transparent.png\" alt=\"SUT Logo\" width=\"140\">\n",
                "  </a>\n",
                "  \n",
                "  # Sharif University of Technology\n",
                "  ### Electrical Engineering Department\n",
                "\n",
                "  ## Signals and Systems\n",
                "  #### *Final Project - Spring 2025*\n",
                "</div>\n",
                "\n",
                "---\n",
                "\n",
                "<div align=\"center\">\n",
                "  <h1>\n",
                "    <b>Object Tracker</b>\n",
                "  </h1>\n",
                "  <p>\n",
                "    An object tracking system using YOLO for detection and various algorithms (KCF, CSRT, MOSSE) for tracking.\n",
                "  </p>\n",
                "</div>\n",
                "\n",
                "<br>\n",
                "\n",
                "| Professor                  |\n",
                "| :-------------------------: |\n",
                "| Dr. Mohammad Mehdi Mojahedian |\n",
                "\n",
                "<br>\n",
                "\n",
                "| Contributors              |\n",
                "| :-----------------------: |\n",
                "| **Amirreza Mousavi** |\n",
                "| **Mahdi Falahi** |\n",
                "| **Zahra Miladipour** |"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f6017895",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "70e8b3de",
            "metadata": {},
            "source": [
                "# 0: Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0d3b8cc9",
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "from ultralytics import YOLO\n",
                "import time\n",
                "import torch\n",
                "from scipy.optimize import linear_sum_assignment"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "427bd61d",
            "metadata": {},
            "source": [
                "# 1: Object Detection"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8186abf2",
            "metadata": {},
            "source": [
                "## Preparing Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "be5a1c83",
            "metadata": {},
            "outputs": [],
            "source": [
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\"ObjectTracker using device: {device}\")\n",
                "model = YOLO('./yolo11n.pt').to(device)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "153643a7",
            "metadata": {},
            "source": [
                "## ObjectTracker Class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "feb41a98",
            "metadata": {},
            "outputs": [],
            "source": [
                "class ObjectTracker:\n",
                "    def __init__(self, model, tracker_type='KCF', detect_interval=48, conf_threshold=0.5, iou_threshold=0.7, max_lost_frames=5, max_objects=10, use_kalman=True):\n",
                "        self.model = model\n",
                "        self.detect_interval = detect_interval\n",
                "        self.conf_threshold = conf_threshold\n",
                "        self.iou_threshold = iou_threshold\n",
                "        self.max_lost_frames = max_lost_frames\n",
                "        self.max_objects = max_objects\n",
                "        self.use_kalman = use_kalman\n",
                "        self.frame_idx = 0\n",
                "        self.tracked_objects = []\n",
                "        self.next_track_id = 0\n",
                "\n",
                "        self.tracker_constructors = {\n",
                "            'CSRT': cv2.legacy.TrackerCSRT_create,\n",
                "            'KCF': cv2.legacy.TrackerKCF_create,\n",
                "            'MOSSE': cv2.legacy.TrackerMOSSE_create,\n",
                "            'MEDIAN_FLOW': cv2.legacy.TrackerMedianFlow_create\n",
                "        }\n",
                "        if tracker_type not in self.tracker_constructors:\n",
                "            raise ValueError(f\"Invalid tracker type: {tracker_type}. Choose from {list(self.tracker_constructors.keys())}\")\n",
                "        self.tracker_type = tracker_type\n",
                "        print(f\"Using tracker: {self.tracker_type}\")\n",
                "\n",
                "    def process_frame(self, frame):\n",
                "        height, width = frame.shape[:2]\n",
                "\n",
                "        self._predict_phase(height, width)\n",
                "        lost_track_detected = self._update_phase(frame)\n",
                "        self._cleanup_and_detect_phase(frame, self.iou_threshold, self.max_lost_frames, lost_track_detected, self.max_objects)\n",
                "        annotated_frame = self._drawing_phase(frame)\n",
                "\n",
                "        self.frame_idx += 1\n",
                "        return annotated_frame\n",
                "\n",
                "    def _predict_phase(self, height, width):\n",
                "        for obj in self.tracked_objects:\n",
                "            obj['kf'].predict()\n",
                "            predicted_state = obj['kf'].statePost\n",
                "            cx, cy, w, h = predicted_state[0], predicted_state[1], predicted_state[2], predicted_state[3]\n",
                "            obj['bbox'] = (int(cx - w/2), int(cy - h/2), int(cx + w/2), int(cy + h/2))\n",
                "\n",
                "            x1, y1, x2, y2 = obj['bbox']\n",
                "            if x2 < 0 or y2 < 0 or x1 > width or y1 > height:\n",
                "                obj['lost_frames'] = self.max_lost_frames\n",
                "            elif max(0, min(x2, width) - max(x1, 0)) * max(0, min(y2, height) - max(y1, 0)) < 0.1 * (x2 - x1) * (y2 - y1):\n",
                "                obj['lost_frames'] += 1\n",
                "            obj['bbox'] = (max(0, x1), max(0, y1), min(width, x2), min(height, y2))\n",
                "\n",
                "    def _update_phase(self, frame):\n",
                "        lost_track_detected = False\n",
                "        for obj in self.tracked_objects:\n",
                "            success, bbox = obj['tracker'].update(frame)\n",
                "            if success:\n",
                "                x1, y1, w, h = [int(v) for v in bbox]\n",
                "                cx, cy = x1 + w/2, y1 + h/2\n",
                "                measurement = np.array([cx, cy, w, h], dtype=np.float32)\n",
                "                obj['kf'].correct(measurement)\n",
                "                obj['bbox'] = (x1, int(y1), int(x1 + w), int(y1 + h))\n",
                "                obj['lost_frames'] = 0\n",
                "            else:\n",
                "                obj['lost_frames'] += 1\n",
                "                lost_track_detected = True\n",
                "        return lost_track_detected\n",
                "\n",
                "    def _cleanup_and_detect_phase(self, frame, iou_threshold, max_lost_frames, lost_track_detected, max_objects):\n",
                "        self.tracked_objects = [t for t in self.tracked_objects if t['lost_frames'] < max_lost_frames]\n",
                "\n",
                "        if lost_track_detected or (self.frame_idx % self.detect_interval == 0):\n",
                "            detections = self.detect(frame)\n",
                "            \n",
                "            if detections:\n",
                "                tracked_bboxes = [t['bbox'] for t in self.tracked_objects]\n",
                "                detected_bboxes = [[d['x1'], d['y1'], d['x2'], d['y2']] for d in detections]\n",
                "                \n",
                "                iou_matrix = self._calculate_iou(tracked_bboxes, detected_bboxes)\n",
                "                matched_pairs, _, unmatched_detections = self._apply_matching(iou_matrix, iou_threshold)\n",
                "\n",
                "                for t_idx, d_idx in matched_pairs:\n",
                "                    track = self.tracked_objects[t_idx]\n",
                "                    det = detections[d_idx]\n",
                "                    x1, y1, x2, y2 = det['x1'], det['y1'], det['x2'], det['y2']\n",
                "                    w, h = x2 - x1, y2 - y1\n",
                "                    cx, cy = x1 + w/2, y1 + h/2\n",
                "                    measurement = np.array([cx, cy, w, h], dtype=np.float32)\n",
                "                    track['kf'].correct(measurement)\n",
                "                    track['tracker'].init(frame, (x1, y1, w, h))\n",
                "                    track['bbox'] = (x1, y1, x2, y2)\n",
                "                    track['lost_frames'] = 0\n",
                "                        \n",
                "    def _drawing_phase(self, frame):\n",
                "        objects_to_draw = []\n",
                "        for obj in self.tracked_objects:\n",
                "            state = obj['kf'].statePost\n",
                "            cx, cy, w, h = state[0], state[1], state[2], state[3]\n",
                "            x1, y1, x2, y2 = int(cx-w/2), int(cy-h/2), int(cx+w/2), int(cy+h/2)\n",
                "            \n",
                "            objects_to_draw.append({\n",
                "                'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2,\n",
                "                'class_name': f\"ID-{obj['id']} {obj['class_name']}\",\n",
                "                'conf': obj.get('conf', 1.0), 'color': obj['color']\n",
                "            })\n",
                "        \n",
                "        annotated_frame = self.draw_boxes(frame, objects_to_draw)\n",
                "        return annotated_frame\n",
                "\n",
                "    def add_manual_track(self, frame, bbox, class_name):\n",
                "        x1, y1, x2, y2 = [int(c) for c in bbox]\n",
                "        w, h = x2 - x1, y2 - y1\n",
                "\n",
                "        if w <= 0 or h <= 0:\n",
                "            print(f\"Warning: Invalid bbox {bbox}. Skipping.\")\n",
                "            return\n",
                "\n",
                "        print(f\"Adding new manual track for '{class_name}' at {(x1, y1, w, h)}\")\n",
                "        \n",
                "        new_kf = self._create_kalman_filter()\n",
                "        new_kf.statePost = np.array([x1 + w/2, y1 + h/2, w, h, 0, 0, 0, 0], dtype=np.float32)\n",
                "        \n",
                "        tracker = self.tracker_constructors[self.tracker_type]()\n",
                "        tracker.init(frame, (x1, y1, w, h))\n",
                "        \n",
                "        self.tracked_objects.append({\n",
                "            'id': self.next_track_id, 'kf': new_kf, 'tracker': tracker,\n",
                "            'class_name': class_name, 'conf': 1.0,\n",
                "            'color': np.random.uniform(0, 255, 3).tolist(), 'bbox': (x1, y1, x2, y2),\n",
                "            'lost_frames': 0\n",
                "        })\n",
                "        self.next_track_id += 1\n",
                "\n",
                "    def detect(self, frame):\n",
                "        results = self.model(frame, verbose=False)[0]\n",
                "        detections = []\n",
                "        for box in results.boxes:\n",
                "            conf = box.conf[0].item()\n",
                "            if conf > self.conf_threshold:\n",
                "                class_name = self.model.names[int(box.cls[0].item())]\n",
                "                coords = box.xyxy[0].tolist()\n",
                "                detections.append({\n",
                "                    'class_name': class_name,\n",
                "                    'x1': int(coords[0]), 'y1': int(coords[1]),\n",
                "                    'x2': int(coords[2]), 'y2': int(coords[3]),\n",
                "                    'conf': conf\n",
                "                })\n",
                "        return detections\n",
                "\n",
                "    def _calculate_iou(self, bboxes1, bboxes2):\n",
                "        bboxes1 = np.array(bboxes1)\n",
                "        bboxes2 = np.array(bboxes2)\n",
                "        if bboxes1.size == 0 or bboxes2.size == 0:\n",
                "            return np.empty((len(bboxes1), len(bboxes2)))\n",
                "        xA = np.maximum(bboxes1[:, 0][:, np.newaxis], bboxes2[:, 0])\n",
                "        yA = np.maximum(bboxes1[:, 1][:, np.newaxis], bboxes2[:, 1])\n",
                "        xB = np.minimum(bboxes1[:, 2][:, np.newaxis], bboxes2[:, 2])\n",
                "        yB = np.minimum(bboxes1[:, 3][:, np.newaxis], bboxes2[:, 3])\n",
                "        interArea = np.maximum(0, xB - xA) * np.maximum(0, yB - yA)\n",
                "        boxAArea = (bboxes1[:, 2] - bboxes1[:, 0]) * (bboxes1[:, 3] - bboxes1[:, 1])\n",
                "        boxBArea = (bboxes2[:, 2] - bboxes2[:, 0]) * (bboxes2[:, 3] - bboxes2[:, 1])\n",
                "        iou = interArea / (boxAArea[:, np.newaxis] + boxBArea - interArea + 1e-6)\n",
                "        return iou\n",
                "    \n",
                "    def _create_kalman_filter(self):\n",
                "        kf = cv2.KalmanFilter(8, 4)\n",
                "        kf.transitionMatrix = np.array([[1,0,0,0,1,0,0,0],[0,1,0,0,0,1,0,0],[0,0,1,0,0,0,1,0],[0,0,0,1,0,0,0,1],[0,0,0,0,1,0,0,0],[0,0,0,0,0,1,0,0],[0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,1]], np.float32)\n",
                "        kf.measurementMatrix = np.array([[1,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0],[0,0,1,0,0,0,0,0],[0,0,0,1,0,0,0,0]], np.float32)\n",
                "        kf.processNoiseCov = np.eye(8, dtype=np.float32) * 0.03\n",
                "        kf.processNoiseCov[4:, 4:] *= 10\n",
                "        kf.measurementNoiseCov = np.eye(4, dtype=np.float32) * 0.1\n",
                "        return kf\n",
                "\n",
                "    def _apply_matching(self, iou_matrix, iou_threshold):\n",
                "        if iou_matrix.size == 0:\n",
                "            return [], [], list(range(0))\n",
                "        cost_matrix = 1 - iou_matrix\n",
                "        track_indices, detection_indices = linear_sum_assignment(cost_matrix)\n",
                "        matched_pairs = []\n",
                "        unmatched_track_indices = set(range(iou_matrix.shape[0]))\n",
                "        unmatched_detection_indices = set(range(iou_matrix.shape[1]))\n",
                "        for t_idx, d_idx in zip(track_indices, detection_indices):\n",
                "            if iou_matrix[t_idx, d_idx] >= iou_threshold:\n",
                "                matched_pairs.append((t_idx, d_idx))\n",
                "                unmatched_track_indices.discard(t_idx)\n",
                "                unmatched_detection_indices.discard(d_idx)\n",
                "        return matched_pairs, list(unmatched_track_indices), list(unmatched_detection_indices)\n",
                "\n",
                "    def draw_boxes(self, frame, objects, default_color='random'):\n",
                "        frame_copy = frame.copy()\n",
                "        for obj in objects:\n",
                "            x1, y1, x2, y2 = obj['x1'], obj['y1'], obj['x2'], obj['y2']\n",
                "            label = f\"{obj['class_name']} {obj['conf']:.2f}\"\n",
                "            box_color = obj.get('color', np.random.uniform(0, 255, 3).tolist())\n",
                "            cv2.rectangle(frame_copy, (x1, y1), (x2, y2), box_color, 2)\n",
                "            cv2.putText(frame_copy, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, box_color, 2)\n",
                "        return frame_copy"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c2f61c42",
            "metadata": {},
            "source": [
                "## Sample Detection Test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "09da1649",
            "metadata": {},
            "outputs": [],
            "source": [
                "# test_img = cv2.imread('./assets/images/0001.jpg')\n",
                "\n",
                "# test_tracker = ObjectTracker(model)\n",
                "# test_img_detections = test_tracker.detect(test_img)\n",
                "# test_tracker.plot_image(test_tracker.draw_boxes(test_img, test_img_detections))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "77598323",
            "metadata": {},
            "source": [
                "# 2: Tracking"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4eb94019",
            "metadata": {},
            "source": [
                "## VideoPlayer class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c0e49fee",
            "metadata": {},
            "outputs": [],
            "source": [
                "class VideoPlayer:\n",
                "    def __init__(self, source, size_multiplier=1.0, playback_speed=1.0, window_title=\"Video Playback\"):\n",
                "        self.cap = cv2.VideoCapture(source)\n",
                "        self.window_title = window_title\n",
                "        \n",
                "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
                "        self.frame_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
                "        self.frame_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
                "        \n",
                "        self.target_delay_ms = (1000 / self.fps) / playback_speed if self.fps > 0 else 33\n",
                "\n",
                "        # --- State and Interaction Management ---\n",
                "        self.state = 'INITIALIZING'\n",
                "        self.selectable_detections = []\n",
                "        self.user_selections = []\n",
                "        self.is_drawing_roi = False\n",
                "        self.roi_start_point = None\n",
                "        self.roi_end_point = None\n",
                "        self.new_manual_box = None\n",
                "        self.show_help = True\n",
                "        self.YOLO_CLASSES = {\n",
                "            0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', \n",
                "            5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light',\n",
                "            10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench',\n",
                "            14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow',\n",
                "            20: 'other' # Added 'other' class\n",
                "        }\n",
                "        \n",
                "        cv2.namedWindow(self.window_title, cv2.WINDOW_NORMAL)\n",
                "        cv2.resizeWindow(self.window_title, int(self.frame_width * size_multiplier), int(self.frame_height * size_multiplier))\n",
                "        \n",
                "        cv2.setMouseCallback(self.window_title, self._mouse_callback)\n",
                "        print(\"--- Video Player Initialized for Interactive Tracking ---\")\n",
                "\n",
                "    def _mouse_callback(self, event, x, y, flags, param):\n",
                "        if self.state != 'PAUSED_FOR_SELECTION': return\n",
                "\n",
                "        if event == cv2.EVENT_LBUTTONDOWN:\n",
                "            self.is_drawing_roi = True\n",
                "            self.roi_start_point = (x, y)\n",
                "            self.roi_end_point = (x, y)\n",
                "\n",
                "        elif event == cv2.EVENT_MOUSEMOVE:\n",
                "            if self.is_drawing_roi: self.roi_end_point = (x, y)\n",
                "\n",
                "        elif event == cv2.EVENT_LBUTTONUP:\n",
                "            if self.is_drawing_roi:\n",
                "                self.is_drawing_roi = False\n",
                "                if self.roi_end_point and self.roi_start_point and abs(self.roi_start_point[0] - self.roi_end_point[0]) > 5:\n",
                "                    x1, y1 = self.roi_start_point\n",
                "                    x2, y2 = self.roi_end_point\n",
                "                    self.new_manual_box = (min(x1, x2), min(y1, y2), max(x1, x2), max(y1, y2))\n",
                "                self.roi_start_point = None\n",
                "                self.roi_end_point = None\n",
                "\n",
                "        elif event == cv2.EVENT_RBUTTONDOWN:\n",
                "            removed_selection = False\n",
                "            for i, sel in reversed(list(enumerate(self.user_selections))):\n",
                "                bbox = sel.get('bbox') or (sel['x1'], sel['y1'], sel['x2'], sel['y2'])\n",
                "                if bbox[0] < x < bbox[2] and bbox[1] < y < bbox[3]:\n",
                "                    removed_item = self.user_selections.pop(i)\n",
                "                    if 'x1' in removed_item: self.selectable_detections.append(removed_item)\n",
                "                    removed_selection = True\n",
                "                    break\n",
                "            \n",
                "            if not removed_selection:\n",
                "                for i, det in reversed(list(enumerate(self.selectable_detections))):\n",
                "                    if det['x1'] < x < det['x2'] and det['y1'] < y < det['y2']:\n",
                "                        self.user_selections.append(self.selectable_detections.pop(i))\n",
                "                        break\n",
                "\n",
                "    def _draw_pause_menu(self, frame):\n",
                "        overlay = frame.copy()\n",
                "        # Full-width semi-transparent background for the menu\n",
                "        cv2.rectangle(overlay, (0, 0), (frame.shape[1], 210), (0, 0, 0), -1)\n",
                "        frame = cv2.addWeighted(overlay, 0.7, frame, 0.3, 0)\n",
                "\n",
                "        # Menu Title (Larger and Bolder)\n",
                "        cv2.putText(frame, \"PAUSED - SELECTION MODE\", (25, 55), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0, 255, 255), 3)\n",
                "        \n",
                "        # Instructions (Larger and Bolder)\n",
                "        cv2.putText(frame, \"Mouse Controls:\", (25, 105), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
                "        cv2.putText(frame, \"- Left-Click & Drag: Draw a new box to track\", (35, 135), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
                "        cv2.putText(frame, \"- Right-Click: Select a red box / Deselect a green box\", (35, 160), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
                "\n",
                "        cv2.putText(frame, \"Keyboard: C: Confirm | H: Toggle Help | Space: Pause | Q: Quit\", (25, 195), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
                "        \n",
                "        return frame\n",
                "    \n",
                "    def _get_numeric_input(self, frame):\n",
                "        num_input = \"\"\n",
                "        while True:\n",
                "            frame_copy = frame.copy()\n",
                "            overlay = frame_copy.copy()\n",
                "            cv2.rectangle(overlay, (0, 0), (frame_copy.shape[1], frame_copy.shape[0]), (0, 0, 0), -1)\n",
                "            frame_copy = cv2.addWeighted(overlay, 0.85, frame_copy, 0.15, 0)\n",
                "\n",
                "            # --- New: Highlight selected class in green ---\n",
                "            current_selection_id = -1\n",
                "            try:\n",
                "                if num_input: current_selection_id = int(num_input)\n",
                "            except ValueError: pass\n",
                "\n",
                "            cv2.putText(frame_copy, \"Enter Class ID & Press Enter:\", (50, 60), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0, 255, 255), 3)\n",
                "            y_offset = 120\n",
                "            for i, name in self.YOLO_CLASSES.items():\n",
                "                if y_offset < frame.shape[0] - 30:\n",
                "                    color = (0, 255, 0) if i == current_selection_id else (255, 255, 255)\n",
                "                    thickness = 3 if i == current_selection_id else 2\n",
                "                    cv2.putText(frame_copy, f\"{i}: {name}\", (50, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, thickness)\n",
                "                    y_offset += 40\n",
                "            \n",
                "            cv2.imshow(self.window_title, frame_copy)\n",
                "            \n",
                "            key = cv2.waitKey(0)\n",
                "            if key == 13: # Enter\n",
                "                try:\n",
                "                    if num_input and int(num_input) in self.YOLO_CLASSES: return int(num_input)\n",
                "                    else: print(f\"Error: Invalid ID. Please try again.\"); num_input = \"\"\n",
                "                except ValueError: print(\"Error: Invalid input.\"); num_input = \"\"\n",
                "            elif key == 8: num_input = num_input[:-1]\n",
                "            elif ord('0') <= key <= ord('9'): num_input += chr(key)\n",
                "            elif key == 27: return None # Escape key\n",
                "\n",
                "    def play(self, tracker):\n",
                "        frame_idx = 0\n",
                "        temp_frame = None\n",
                "\n",
                "        while True:\n",
                "            if self.state in ['INITIALIZING', 'PLAYING']:\n",
                "                ret, frame = self.cap.read()\n",
                "                if not ret: break\n",
                "                temp_frame = frame.copy()\n",
                "                frame_idx += 1\n",
                "            else: frame = temp_frame.copy()\n",
                "\n",
                "            if self.state == 'INITIALIZING' and frame_idx == 2:\n",
                "                self.state = 'PAUSED_FOR_SELECTION'\n",
                "                self.selectable_detections = tracker.detect(frame)\n",
                "\n",
                "            elif self.state == 'PLAYING':\n",
                "                processed_frame = tracker.process_frame(frame)\n",
                "                cv2.imshow(self.window_title, processed_frame)\n",
                "\n",
                "            elif self.state == 'PAUSED_FOR_SELECTION':\n",
                "                display_frame = frame.copy()\n",
                "                if self.show_help: display_frame = self._draw_pause_menu(display_frame)\n",
                "                \n",
                "                for det in self.selectable_detections: cv2.rectangle(display_frame, (det['x1'], det['y1']), (det['x2'], det['y2']), (0, 0, 255), 2)\n",
                "                for sel in self.user_selections:\n",
                "                    bbox = sel.get('bbox') or (sel['x1'], sel['y1'], sel['x2'], sel['y2'])\n",
                "                    cv2.rectangle(display_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 3)\n",
                "                if self.is_drawing_roi and self.roi_start_point and self.roi_end_point:\n",
                "                    cv2.rectangle(display_frame, self.roi_start_point, self.roi_end_point, (255, 255, 0), 2)\n",
                "                \n",
                "                cv2.imshow(self.window_title, display_frame)\n",
                "\n",
                "                if self.new_manual_box:\n",
                "                    class_id = self._get_numeric_input(display_frame)\n",
                "                    if class_id is not None:\n",
                "                        self.user_selections.append({'bbox': self.new_manual_box, 'class_name': self.YOLO_CLASSES[class_id]})\n",
                "                    self.new_manual_box = None\n",
                "\n",
                "            key = cv2.waitKey(1 if self.state == 'PLAYING' else 20) & 0xFF\n",
                "            if key == ord('q'): break\n",
                "            elif key == ord('h'): self.show_help = not self.show_help\n",
                "            elif key == 32 and self.state == 'PLAYING': # Spacebar to pause\n",
                "                print(\"Paused. Entering selection mode...\")\n",
                "                self.state = 'PAUSED_FOR_SELECTION'\n",
                "                self.selectable_detections = tracker.detect(frame)\n",
                "                self.user_selections = list(tracker.tracked_objects)\n",
                "\n",
                "            elif key == ord('c') and self.state == 'PAUSED_FOR_SELECTION':\n",
                "                print(\"Selections confirmed. Resuming tracking...\")\n",
                "                tracker.tracked_objects = [] \n",
                "                tracker.next_track_id = 0\n",
                "                for sel in self.user_selections:\n",
                "                    bbox = sel.get('bbox') or (sel['x1'], sel['y1'], sel['x2'], sel['y2'])\n",
                "                    tracker.add_manual_track(temp_frame, bbox, sel['class_name'])\n",
                "                \n",
                "                self.selectable_detections = []\n",
                "                self.user_selections = []\n",
                "                self.state = 'PLAYING'\n",
                "\n",
                "        self.release()\n",
                "\n",
                "    def release(self):\n",
                "        print(\"Releasing resources...\")\n",
                "        if self.cap.isOpened(): self.cap.release()\n",
                "        cv2.destroyAllWindows()\n",
                "        for _ in range(5): cv2.waitKey(1)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ff4ec198",
            "metadata": {},
            "source": [
                "## Test Playback"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3adef366",
            "metadata": {},
            "outputs": [],
            "source": [
                "# You can change these parameters\n",
                "VIDEO_PATH = './assets/footage/person4.mp4' # Make sure this path is correct\n",
                "MODEL_PATH = './yolo11n.pt'\n",
                "PLAYBACK_SPEED = 1.5 # Play at 1.5x speed\n",
                "WINDOW_SIZE = 0.5   # Display window at 75% of original size\n",
                "\n",
                "try:\n",
                "    tracker = ObjectTracker(model, 'CSRT')\n",
                "    player = VideoPlayer(\n",
                "        source=VIDEO_PATH,\n",
                "        playback_speed=PLAYBACK_SPEED,\n",
                "        size_multiplier=WINDOW_SIZE,\n",
                "        window_title=\"High-Performance Player\"\n",
                "    )\n",
                "    player.play(tracker)\n",
                "except IOError as e:\n",
                "    print(e)\n",
                "except Exception as e:\n",
                "    print(f\"An unexpected error occurred: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "signalenv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
