{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <a href=\"http://www.sharif.edu/\">\n",
    "    <img src=\"https://cdn.freebiesupply.com/logos/large/2x/sharif-logo-png-transparent.png\" alt=\"SUT Logo\" width=\"140\">\n",
    "  </a>\n",
    "  \n",
    "  # Sharif University of Technology\n",
    "  ### Electrical Engineering Department\n",
    "\n",
    "  ## Signals and Systems\n",
    "  #### *Final Project - Spring 2025*\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "  <h1>\n",
    "    <b>Object Tracker</b>\n",
    "  </h1>\n",
    "  <p>\n",
    "    An object tracking system using YOLO for detection and various algorithms (KCF, CSRT, MOSSE) for tracking.\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "| Professor                  |\n",
    "| :-------------------------: |\n",
    "| Dr. Mohammad Mehdi Mojahedian |\n",
    "\n",
    "<br>\n",
    "\n",
    "| Contributors              |\n",
    "| :-----------------------: |\n",
    "| **Amirreza Mousavi** |\n",
    "| **Mahdi Falahi** |\n",
    "| **Zahra Miladipour** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1: Preparing The Materials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 : Calculating HOG ( return the hog of the image)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_scaling (image):\n",
    "    img = cv2.cvtColor(image ,cv2.COLOR_BGR2GRAY)\n",
    "    filter = cv2.HOGDescriptor((64, 64), (16, 16), (8, 8), (8, 8), 9)\n",
    "    resized_image = cv2.resize(img, (64, 64))\n",
    "    result = filter.compute(resized_image)\n",
    "    return result if result is not None else np.zeros((hog_descriptor.getDescriptorSize(1764),))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_channel(image):\n",
    "    img = cv2.cvtColor(image , cv2.COLOR_BGR2GRAY)\n",
    "    win_size = (image.shape[1], image.shape[0])\n",
    "    filter = cv2.HOGDescriptor(win_size , (16 ,16 ) , (8,8) , (8,8) , 9)\n",
    "    result = filter.compute(img)\n",
    "    height =  (win_size[1] - 16) // 8 + 1    # 8 is the block strid(x) we can change that consider the trade off of time _ accuracy\n",
    "    width = (win_size[0] - 16) // 8 + 1   # 8 is the block strid(y) we can change that consider the trade off of time _ accuracy\n",
    "    features_per_block = 2 * 2 * 9\n",
    "    hog_features = result.reshape((height, width, features_per_block))\n",
    "    return cv2.resize(hog_features, (win_size[0] // 8, win_size[1] // 8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 : Checking The Scale (return the scale of the image in the current frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_check(frame, pos, base_size, scale_factors, scale_model_A, scale_model_B, lambda_trust=0.01):\n",
    "    scale_features = []\n",
    "    for scale in scale_factors:\n",
    "        w_s, h_s = int(base_size[0] * scale), int(base_size[1] * scale)\n",
    "        x_s, y_s = int(pos[0] - w_s / 2), int(pos[1] - h_s / 2)\n",
    "        patch_s = frame[y_s:y_s+h_s, x_s:x_s+w_s]\n",
    "        if patch_s.shape[0] < 16 or patch_s.shape[1] < 16:\n",
    "            scale_features.append(np.zeros_like(scale_features[0]) if len(scale_features) > 0 else np.zeros((1764,)))\n",
    "            continue\n",
    "        resized = cv2.resize(patch_s, (64, 64))\n",
    "        scale_features.append(hog_scaling(resized))\n",
    "    \n",
    "    SF = np.fft.fft(np.array(scale_features), axis=0)\n",
    "    scale_H = scale_model_A / (scale_model_B[:, np.newaxis] + lambda_trust)\n",
    "    response_f = np.sum(np.conj(scale_H) * SF, axis=1)\n",
    "    response = np.real(np.fft.ifft(response_f))\n",
    "    \n",
    "    best_scale_idx = np.argmax(response)\n",
    "    return scale_factors[best_scale_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 : Prediction The Next Frame's Center ( Kalman Filter )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_prediction( F , X_k_1 , P_k_1 , Q_k):\n",
    "    x_k = np.dot(F , X_k_1)\n",
    "    p_k = np.dot( F , np.dot(P_k_1 , F.T)) + Q_k\n",
    "    return x_k , p_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_updating(x_k , p_k , H_k , z_k , R_k):\n",
    "    k_1 = np.dot(np.dot(H_k , p_k) , H_k.T) + R_k\n",
    "    k_2 = np.dot(p_k , H_k.T)\n",
    "    K = np.dot(k_2 , np.linalg.inv(k_1))\n",
    "    P_k_new = p_k - np.dot(np.dot(K , H_k) , p_k)\n",
    "    x_k_new = x_k + np.dot(K , (z_k - np.dot(H_k , x_k)))\n",
    "    return x_k_new , P_k_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 : Updating Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_updating(H_new , H_old , alpha):\n",
    "    result = alpha * H_new + (1-alpha) * H_old\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 : Finding The Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_channels(image):\n",
    "    hog_features = hog_channel(image)\n",
    "    colors = np.array([\n",
    "        [0.00, 0.00, 0.00], [45.37, -4.33, -33.43], [43.08, 17.51, 37.53],\n",
    "        [53.59, 0.00, 0.00], [47.31, -45.33, 41.35], [65.75, 71.45, 63.32],\n",
    "        [76.08, 22.25, -21.46], [32.30, 79.19, -107.86], [52.23, 75.43, 37.36],\n",
    "        [100.00, 0.00, 0.00], [92.13, -16.53, 93.35]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)\n",
    "    pixels = image_lab.reshape(-1, 3).astype(np.float32)\n",
    "    distances = np.sum((pixels[:, np.newaxis, :] - colors[np.newaxis, :, :]) ** 2, axis=2)\n",
    "    closest_color_indices = np.argmin(distances, axis=1)\n",
    "    \n",
    "    cn_features_flat = np.zeros((pixels.shape[0], colors.shape[0]), dtype=np.float32)\n",
    "    cn_features_flat[np.arange(pixels.shape[0]), closest_color_indices] = 1\n",
    "    cn_features = cn_features_flat.reshape(image.shape[0], image.shape[1], -1)\n",
    "\n",
    "    hog_resized = cv2.resize(hog_features, (image.shape[1], image.shape[0]))\n",
    "    return np.dstack((hog_resized, cn_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6 : Teaching The Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teaching ( f , g , lambda_trust):\n",
    "    X = np.fft.fft2(f , axes = (0 ,1 ))\n",
    "    G = np.fft.fft2(g)\n",
    "    G1 = np.expand_dims(G , axis = 2)\n",
    "    num = np.conj(X) * G1\n",
    "    denom = np.sum(np.conj(X) * X , axis =2) + lambda_trust\n",
    "    return num, denom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psr(response_map):\n",
    "    if not isinstance(response_map, np.ndarray) or response_map.size == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    peak_loc = np.unravel_index(np.argmax(response_map), response_map.shape)\n",
    "    peak_value = response_map[peak_loc]\n",
    "\n",
    "    sidelobe_window = 11\n",
    "    h, w = response_map.shape\n",
    "    y_start = max(0, peak_loc[0] - sidelobe_window // 2)\n",
    "    y_end = min(h, peak_loc[0] + sidelobe_window // 2 + 1)\n",
    "    x_start = max(0, peak_loc[1] - sidelobe_window // 2)\n",
    "    x_end = min(w, peak_loc[1] + sidelobe_window // 2 + 1)\n",
    "    \n",
    "    mask = np.ones_like(response_map, dtype=bool)\n",
    "    mask[y_start:y_end, x_start:x_end] = False\n",
    "    \n",
    "    sidelobe = response_map[mask]\n",
    "    \n",
    "    if sidelobe.size > 0:\n",
    "        mean_sidelobe = np.mean(sidelobe)\n",
    "        std_sidelobe = np.std(sidelobe)\n",
    "        if std_sidelobe > 1e-5:\n",
    "            return (peak_value - mean_sidelobe) / std_sidelobe\n",
    "    return 0.0\n",
    "\n",
    "def create_gaussian_target(size, center_x, center_y, sigma=18.0):\n",
    "    height, width = size\n",
    "    yy, xx = np.mgrid[0:height, 0:width]\n",
    "    gaussian = np.exp(-((xx - center_x)**2 + (yy - center_y)**2) / (2 * sigma**2))\n",
    "    rolled_gaussian = np.roll(np.roll(gaussian, -center_y, axis=0), -center_x, axis=1)\n",
    "    return rolled_gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 : Main Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 : Uploading Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('person4.mp4')\n",
    "model = YOLO('yolo11n.pt')\n",
    "if not cap.isOpened():\n",
    "    print(\"wrong video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 : The Main Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking = False\n",
    "frames_since_update = 0\n",
    "MAX_FRAMES_TO_SKIP = 30\n",
    "RE_DETECTION_FRAME_THRESHOLD = 5 \n",
    "CONFIDENCE_THRESHOLD = 0.5 # آستانه اطمینان برای تشخیص اصلی و مجدد\n",
    "\n",
    "model_A, model_B = None, None\n",
    "scale_model_A, scale_model_B = None, None\n",
    "current_pos, current_size = (0, 0), (0, 0)\n",
    "fixed_roi_size = (64, 128)\n",
    "\n",
    "dt = 1/30.0 \n",
    "F = np.array([[1, dt, 0, 0], [0, 1, 0, 0], [0, 0, 1, dt], [0, 0, 0, 1]], dtype=np.float32)\n",
    "H = np.array([[1, 0, 0, 0], [0, 0, 1, 0]], dtype=np.float32)\n",
    "Q = np.eye(4, dtype=np.float32) * 1e-2\n",
    "R = np.eye(2, dtype=np.float32) * 25\n",
    "P = np.eye(4, dtype=np.float32) * 100\n",
    "kalman_state = np.zeros(4, dtype=np.float32)\n",
    "\n",
    "last_time = 0; fps = 0; psr_score = 0.0\n",
    "fps_start_time = time.time(); fps_frame_count = 0\n",
    "\n",
    "# save the output video\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "output_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if output_fps == 0: output_fps = 30.0\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_writer = cv2.VideoWriter('tracking_output.mp4', fourcc, output_fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    current_time = time.time()\n",
    "    dt = (current_time - last_time) if last_time > 0 else 1/30.0\n",
    "    last_time = current_time\n",
    "    \n",
    "    if not tracking:\n",
    "        results = model(frame, verbose=False, classes=[0], conf=CONFIDENCE_THRESHOLD)[0]\n",
    "        if len(results.boxes) > 0:\n",
    "            box = results.boxes[0]\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            current_pos = (x1 + w/2, y1 + h/2); current_size = (w, h)\n",
    "            kalman_state = np.array([current_pos[0], 0, current_pos[1], 0], dtype=np.float32)\n",
    "            patch = cv2.resize(frame[y1:y2, x1:x2], fixed_roi_size)\n",
    "            features = extract_channels(patch)\n",
    "            h_roi, w_roi = fixed_roi_size[1], fixed_roi_size[0]\n",
    "            target_y_2d = create_gaussian_target((h_roi, w_roi), w_roi//2, h_roi//2, 18.0)\n",
    "            model_A, model_B = teaching(features, target_y_2d, 0.01)\n",
    "            tracking = True\n",
    "            frames_since_update = 0\n",
    "    else:\n",
    "        F[0,1]=dt; F[2,3]=dt\n",
    "        kalman_state = F @ kalman_state\n",
    "        P = F @ P @ F.T + Q\n",
    "        pred_pos = (kalman_state[0], kalman_state[2])\n",
    "        \n",
    "        w_search=int(current_size[0]*2.0); h_search=int(current_size[1]*2.0)\n",
    "        x_search=int(pred_pos[0]-w_search/2); y_search=int(pred_pos[1]-h_search/2)\n",
    "        search_patch = frame[max(0,y_search):y_search+h_search, max(0,x_search):x_search+w_search]\n",
    "        \n",
    "        if search_patch.shape[0] > 0 and search_patch.shape[1] > 0:\n",
    "            resized_patch = cv2.resize(search_patch, fixed_roi_size)\n",
    "            features = extract_channels(resized_patch)\n",
    "            Z = np.fft.fft2(features, axes=(0, 1))\n",
    "            H_filter = model_A / (np.expand_dims(model_B, axis=2) + 0.01)\n",
    "            response_f = np.sum(np.conj(H_filter) * Z, axis=2)\n",
    "            response = np.real(np.fft.ifft2(response_f))\n",
    "            psr_score = calculate_psr(response)\n",
    "\n",
    "            if psr_score > 5.5:\n",
    "                frames_since_update = 0\n",
    "                peak_y,peak_x=np.unravel_index(np.argmax(response),response.shape)\n",
    "                if peak_y > fixed_roi_size[1]/2: peak_y -= fixed_roi_size[1]\n",
    "                if peak_x > fixed_roi_size[0]/2: peak_x -= fixed_roi_size[0]\n",
    "                dx=(peak_x/fixed_roi_size[0])*w_search; dy=(peak_y/fixed_roi_size[1])*h_search\n",
    "                measured_pos=(pred_pos[0]+dx, pred_pos[1]+dy)\n",
    "                z=np.array([measured_pos[0],measured_pos[1]],dtype=np.float32)\n",
    "                K=P@H.T@np.linalg.inv(H@P@H.T+R); kalman_state=kalman_state+K@(z-H@kalman_state)\n",
    "                P=(np.eye(4)-K@H)@P; current_pos=(kalman_state[0],kalman_state[2])\n",
    "                \n",
    "                x1_up=int(current_pos[0]-current_size[0]/2); y1_up=int(current_pos[1]-current_size[1]/2)\n",
    "                update_patch = frame[max(0,y1_up):y1_up+int(current_size[1]), max(0,x1_up):x1_up+int(current_size[0])]\n",
    "                if update_patch.shape[0]>0 and update_patch.shape[1]>0:\n",
    "                    resized_patch_up=cv2.resize(update_patch, fixed_roi_size)\n",
    "                    features_new=extract_channels(resized_patch_up)\n",
    "                    target_y_2d=create_gaussian_target(fixed_roi_size[::-1], fixed_roi_size[0]//2, fixed_roi_size[1]//2, 18.0)\n",
    "                    new_A, new_B = teaching(features_new, target_y_2d, 0.01)\n",
    "                    model_A = filter_updating(new_A, model_A, 0.025)\n",
    "                    model_B = filter_updating(new_B, model_B, 0.025)\n",
    "            else:\n",
    "                frames_since_update += 1\n",
    "\n",
    "            if RE_DETECTION_FRAME_THRESHOLD < frames_since_update <= MAX_FRAMES_TO_SKIP:\n",
    "                x,y,w,h = map(int, (pred_pos[0]-current_size[0]/2, pred_pos[1]-current_size[1]/2, current_size[0], current_size[1]))\n",
    "                roi_x1=max(0,x-w); roi_y1=max(0,y-h)\n",
    "                roi_x2=min(frame.shape[1],x+w*2); roi_y2=min(frame.shape[0],y+h*2)\n",
    "                roi_frame = frame[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "\n",
    "                found_good_detection = False\n",
    "                if roi_frame.size > 0:\n",
    "                    roi_results = model(roi_frame, verbose=False, classes=[0], conf=CONFIDENCE_THRESHOLD)[0]\n",
    "                    \n",
    "                    if len(roi_results.boxes) > 0:\n",
    "                        # پیدا کردن بزرگترین تشخیص در ناحیه\n",
    "                        best_det_box = None; max_area = 0\n",
    "                        for r in roi_results.boxes:\n",
    "                            box = r.xyxy[0]; area = (box[2]-box[0])*(box[3]-box[1])\n",
    "                            if area > max_area: max_area = area; best_det_box = box\n",
    "                        \n",
    "                        if best_det_box is not None:\n",
    "                            global_w = int(best_det_box[2]-best_det_box[0])\n",
    "                            global_h = int(best_det_box[3]-best_det_box[1])\n",
    "                            \n",
    "                            # شرط ۲: بررسی ابعاد برای جلوگیری از پرش‌های ناگهانی\n",
    "                            last_area = current_size[0] * current_size[1]\n",
    "                            if last_area > 0 and (global_w * global_h) > 0.25 * last_area:\n",
    "                                global_x1 = int(best_det_box[0]+roi_x1); global_y1 = int(best_det_box[1]+roi_y1)\n",
    "                                current_pos=(global_x1+global_w/2, global_y1+global_h/2)\n",
    "                                current_size=(global_w, global_h)\n",
    "                                kalman_state=np.array([current_pos[0],0,current_pos[1],0],dtype=np.float32)\n",
    "                                patch = cv2.resize(frame[global_y1:global_y1+global_h, global_x1:global_x1+global_w], fixed_roi_size)\n",
    "                                features = extract_channels(patch)\n",
    "                                target_y_2d = create_gaussian_target(fixed_roi_size[::-1], fixed_roi_size[0]//2, fixed_roi_size[1]//2, 18.0)\n",
    "                                model_A, model_B = teaching(features, target_y_2d, 0.01)\n",
    "                                frames_since_update = 0\n",
    "                                found_good_detection = True\n",
    "                \n",
    "                # اگر هیچ تشخیص خوبی پیدا نشد، به پیش‌بینی کالمن اکتفا کن\n",
    "                if not found_good_detection:\n",
    "                    current_pos = pred_pos # بازگشت به پیشنهاد شما\n",
    "\n",
    "        if frames_since_update > MAX_FRAMES_TO_SKIP:\n",
    "            tracking = False\n",
    "        \n",
    "        if tracking:\n",
    "            if frames_since_update == 0:\n",
    "                color = (0, 255, 0); pos_to_draw = current_pos; size_to_draw = current_size\n",
    "            else:\n",
    "                color = (0, 255, 0); pos_to_draw = pred_pos; size_to_draw = current_size\n",
    "            \n",
    "            x_draw = int(pos_to_draw[0]-size_to_draw[0]/2); y_draw = int(pos_to_draw[1]-size_to_draw[1]/2)\n",
    "            w_draw = int(size_to_draw[0]); h_draw = int(size_to_draw[1])\n",
    "            cv2.rectangle(frame, (x_draw, y_draw), (x_draw + w_draw, y_draw + h_draw), color, 2)\n",
    "    \n",
    "    fps_frame_count += 1\n",
    "    if (time.time() - fps_start_time) >= 1.0:\n",
    "        fps = fps_frame_count / (time.time() - fps_start_time)\n",
    "        fps_frame_count = 0\n",
    "        fps_start_time = time.time()\n",
    "\n",
    "    cv2.putText(frame, f\"FPS: {fps:.2f}\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(frame, f\"PSR: {psr_score:.2f}\", (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0) if psr_score > 5.5 else (0,0,255), 2)\n",
    "\n",
    "    cv2.imshow(\"Single Object Tracker\", frame)\n",
    "    out_writer.write(frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27: break\n",
    "        \n",
    "cap.release()\n",
    "out_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
