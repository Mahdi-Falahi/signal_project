{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <a href=\"http://www.sharif.edu/\">\n",
    "    <img src=\"https://cdn.freebiesupply.com/logos/large/2x/sharif-logo-png-transparent.png\" alt=\"SUT Logo\" width=\"140\">\n",
    "  </a>\n",
    "  \n",
    "  # Sharif University of Technology\n",
    "  ### Electrical Engineering Department\n",
    "\n",
    "  ## Signals and Systems\n",
    "  #### *Final Project - Spring 2025*\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "  <h1>\n",
    "    <b>Object Tracker</b>\n",
    "  </h1>\n",
    "  <p>\n",
    "    An object tracking system using YOLO for detection and various algorithms (KCF, CSRT, MOSSE) for tracking.\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "| Professor                  |\n",
    "| :-------------------------: |\n",
    "| Dr. Mohammad Mehdi Mojahedian |\n",
    "\n",
    "<br>\n",
    "\n",
    "| Contributors              |\n",
    "| :-----------------------: |\n",
    "| **Amirreza Mousavi** |\n",
    "| **Mahdi Falahi** |\n",
    "| **Zahra Miladipour** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1: Preparing The Materials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 : Calculating HOG ( return the hog of the image)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_scaling (image):\n",
    "    img = cv2.cvtColor(image ,cv2.COLOR_BGR2GRAY)\n",
    "    filter = cv2.HOGDescriptor()\n",
    "    result = filter.compute(img)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_channel(image):\n",
    "    img = cv2.cvtColor(image , cv2.COLOR_BGR2GRAY)\n",
    "    win_size = (image.shape[1], image.shape[0])\n",
    "    filter = cv2.HOGDescriptor(win_size , (16 ,16 ) , (8,8) , (8,8) , 9)\n",
    "    result = filter.compute(img)\n",
    "    height =  (win_size[1] - 16) // 8 + 1    # 8 is the block strid(x) we can change that consider the trade off of time _ accuracy\n",
    "    width = (win_size[0] - 16) // 8 + 1   # 8 is the block strid(y) we can change that consider the trade off of time _ accuracy\n",
    "    features_per_block = 2 * 2 * 9\n",
    "    hog_features = result.reshape((height, width, features_per_block))\n",
    "    return cv2.resize(hog_features, (win_size[0] // 8, win_size[1] // 8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 : Checking The Scale (return the scale of the image in the current frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_check (image ,h, source_hog):\n",
    "    w , h = image.shape()\n",
    "    n = np.arange(0.9 , 1.2 , 0.05)\n",
    "    source = np.fft.fft2(source_hog)\n",
    "    h_fft = np.fft.fft2(h)\n",
    "    x = h_fft * source\n",
    "    scale = 1\n",
    "    min = 500\n",
    "    for coefficient in n :\n",
    "        new_img = cv2.resize(image , coefficient * w , coefficient * h)\n",
    "        new_fft = np.fft.fft2(new_img)\n",
    "        new_result = new_fft * h_fft\n",
    "        diff = new_result - x\n",
    "        sum = np.sum(diff ** 2)\n",
    "        if (sum < min ):\n",
    "            min = sum\n",
    "            scale = coefficient \n",
    "    return scale    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 : Prediction The Next Frame's Center ( Kalman Filter )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_prediction( F , X_k_1 , P_k_1 , Q_k):\n",
    "    x_k = np.dot(F , X_k_1)\n",
    "    p_k = np.dot( F , np.dot(P_k_1 , F.T)) + Q_k\n",
    "    return x_k , p_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_updating(x_k , p_k , H_k , z_k , R_k):\n",
    "    k_1 = np.dot(np.dot(H_k , p_k) , H_k.T) + R_k\n",
    "    k_2 = np.dot(p_k , H_k.T)\n",
    "    K = np.dot(k_2 , np.linalg.inv(k_1))\n",
    "    P_k_new = p_k - np.dot(np.dot(K , H_k) , p_k)\n",
    "    x_k_new = x_k + np.dot(K , (z_k - np.dot(H_k , x_k)))\n",
    "    return x_k_new , P_k_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 : Updating Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_updating(H_new , H_old , alpha):\n",
    "    result = alpha * H_new + (1-alpha) * H_old\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 : Finding The Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_channels(image):\n",
    "    colors = np.array([\n",
    "    [0.00, 0.00, 0.00], [45.37, -4.33, -33.43], [43.08, 17.51, 37.53],\n",
    "    [53.59, 0.00, 0.00], [47.31, -45.33, 41.35], [65.75, 71.45, 63.32],\n",
    "    [76.08, 22.25, -21.46], [32.30, 79.19, -107.86], [52.23, 75.43, 37.36],\n",
    "    [100.00, 0.00, 0.00], [92.13, -16.53, 93.35]\n",
    "], dtype=np.float32)\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)\n",
    "    h, w, _ = image_lab.shape\n",
    "    num_colors = colors.shape[0]\n",
    "    \n",
    "    new = image_lab.reshape(-1, 3).astype(np.float32)\n",
    "    distances = np.sum((new[:, np.newaxis, :] - colors[np.newaxis, :, :]) ** 2, axis=2)\n",
    "    closest_color_indices = np.argmin(distances, axis=1)\n",
    "    \n",
    "    cn_features_flat = np.zeros((new.shape[0], num_colors), dtype=np.float32)\n",
    "    cn_features_flat[np.arange(new.shape[0]), closest_color_indices] = 1\n",
    "    \n",
    "    cn_features = cn_features_flat.reshape(h, w, num_colors)\n",
    "    return cn_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6 : Teaching The Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teaching ( f , g , lambda_trust):\n",
    "    X = np.fft.fft2(f , axes = (0 ,1 ))\n",
    "    G = np.fft.fft2(g)\n",
    "    G1 = np.expand_dims(G , axis = 2)\n",
    "    num = np.dot(X , G1)\n",
    "    denom = np.sum(np.dot(np.conj(X) , X) , axis =2) + lambda_trust\n",
    "    denomf = np.expand_dims( denom , axis =2)\n",
    "    H = num / denomf \n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 : Main Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 : Uploading Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('person1.mp4')\n",
    "model = YOLO('yolo11n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 : The Main Part"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
